{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "intAbqpKlLOg",
        "iaPwVVH2tOWh",
        "n7ITD6OitcHE",
        "0KeqmPcHrOCn",
        "nEGlxLNjvX2d",
        "Mfs0YC0d2i9B",
        "fwPFPuyN2dbo",
        "wH8WkvWYxwNd",
        "mT4gggQHyGXm"
      ],
      "authorship_tag": "ABX9TyPgZ3+b5mZrh7XRKmZvL25T",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshjoshi23/Object_segmentation_TF/blob/main/Different_Segmentation_Models_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Imports and libraries**"
      ],
      "metadata": {
        "id": "intAbqpKlLOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install segmentation-models-pytorch\n",
        "# Run this cell once before running"
      ],
      "metadata": {
        "id": "uI8x7hl-lTUu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import segmentation_models_pytorch as smp\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "ieTJj1mNlK_K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OryQrpGJlXov"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementing FPN with ResNet 34"
      ],
      "metadata": {
        "id": "iaPwVVH2tOWh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the Model:**"
      ],
      "metadata": {
        "id": "I1CppCcJlYdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the FPN model with ResNet34 encoder\n",
        "model = smp.FPN(\n",
        "    encoder_name=\"resnet34\",        # Choose encoder\n",
        "    encoder_weights=\"imagenet\",     # Use pretrained weights\n",
        "    decoder_pyramid_channels=256,   # Number of convolution filters in FPN\n",
        "    decoder_segmentation_channels=128,  # Number of filters in segmentation blocks\n",
        "    decoder_merge_policy='add',     # Merge policy\n",
        "    decoder_dropout=0.2,            # Spatial dropout rate\n",
        "    in_channels=3,                  # Number of input channels\n",
        "    classes=3,                      # Number of output classes\n",
        "    activation='softmax'            # Activation function\n",
        ")\n"
      ],
      "metadata": {
        "id": "cB-ccEsFlK8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "436ba412-4ad3-4287-a3f5-5fab83f840f0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 221MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating the Input Tensor:**\n",
        "\n"
      ],
      "metadata": {
        "id": "f4mHfr3lqv2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mHzYvuszkmAA"
      },
      "outputs": [],
      "source": [
        "# Define input tensor with random values\n",
        "x = torch.rand(1, 3, 256, 256)  # Example input (batch_size, channels, height, width)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Getting the Output:**"
      ],
      "metadata": {
        "id": "IjMbzz6ZrNom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the model output\n",
        "mask = model(x)\n",
        "\n",
        "# Print the shape of the output\n",
        "print(mask.shape)  # Should be (1, num_classes, height, width)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9eQyJsJqzi0",
        "outputId": "83c21f13-12fe-4f5c-e8b5-d126a2443273"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 256, 256])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V26MvfvJtAkk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Defining the variables**"
      ],
      "metadata": {
        "id": "n7ITD6OitcHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Auxiliary parameters\n",
        "aux_params = dict(\n",
        "    pooling='avg',\n",
        "    dropout=0.5,\n",
        "    activation='sigmoid',\n",
        "    classes=4,\n",
        ")"
      ],
      "metadata": {
        "id": "8CJ7wpnrtber"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining correct decoder_channels for encoder_depth=4\n",
        "\n",
        "decoder_channels = [256, 128, 64, 32]"
      ],
      "metadata": {
        "id": "CBG0bPaAvlcs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OdvMha_vlZ4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detailed Overview of Segmentation Models\n",
        "\n",
        "#### Common Parameters\n",
        "- `encoder_name`: Name of the classification model used as the encoder (e.g., `resnet34`).\n",
        "- `encoder_depth`: Number of stages in the encoder, ranging from 3 to 5.\n",
        "- `encoder_weights`: Pre-trained weights (e.g., `imagenet`).\n",
        "- `decoder_channels`: List of integers specifying the `in_channels` parameter for convolutions in the decoder.\n",
        "- `decoder_use_batchnorm`: Whether to use `BatchNorm2d` in the decoder.\n",
        "- `decoder_attention_type`: Attention module used in the decoder (options: `None`, `scse`).\n",
        "- `in_channels`: Number of input channels (default is 3).\n",
        "- `classes`: Number of classes for the output mask.\n",
        "- `activation`: Activation function applied after the final convolution layer.\n",
        "- `aux_params`: Parameters for auxiliary output (classification head).\n"
      ],
      "metadata": {
        "id": "0Ox723mtus3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code for Different Models**"
      ],
      "metadata": {
        "id": "0KeqmPcHrOCn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Unet\n",
        "- **Class**: `segmentation_models_pytorch.Unet`\n",
        "- **Description**: Unet is a fully convolutional network designed for image semantic segmentation. It consists of an encoder (downsampling) and a decoder (upsampling) connected via skip connections.\n",
        "- **Key Parameters**: See common parameters."
      ],
      "metadata": {
        "id": "nEGlxLNjvX2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model with custom encoder depth and decoder channels\n",
        "model = smp.Unet('resnet34', encoder_depth=4, decoder_channels=decoder_channels, classes=4, aux_params=aux_params)\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(1, 3, 256, 256)  # example input (batch size, channels, height, width)\n",
        "\n",
        "# Get the output\n",
        "mask, label = model(x)\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "print(mask.shape)  # Should be (1, num_classes, height, width)\n",
        "print(label.shape)  # Should be (1, num_aux_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyUvjyIVrOZA",
        "outputId": "b7725746-9815-48c6-c292-6f402fa4df12"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 256, 256])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JPl0aJ1Nxbou"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Unet++\n",
        "- **Class**: `segmentation_models_pytorch.UnetPlusPlus`\n",
        "- **Description**: Unet++ improves upon Unet by using nested and dense skip connections to better capture multi-scale features.\n",
        "- **Key Parameters**: Same as Unet, with a more complex decoder."
      ],
      "metadata": {
        "id": "_x-NcEeiu4TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model with custom encoder depth and decoder channels\n",
        "model = smp.UnetPlusPlus('resnet34', encoder_depth=4, decoder_channels=decoder_channels, classes=4, aux_params=aux_params)\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(1, 3, 256, 256)  # example input (batch size, channels, height, width)\n",
        "\n",
        "# Get the output\n",
        "mask, label = model(x)\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "print(mask.shape)  # Should be (1, num_classes, height, width)\n",
        "print(label.shape)  # Should be (1, num_aux_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efN3QvMeu469",
        "outputId": "b5502f32-b171-45b4-a105-2e335cdee00e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 256, 256])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOfpesGEu4JN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. MAnet\n",
        "- **Class**: `segmentation_models_pytorch.MAnet`\n",
        "- **Description**: Multi-scale Attention Net (MA-Net) captures rich contextual dependencies using Position-wise Attention Block (PAB) and Multi-scale Fusion Attention Block (MFAB).\n",
        "- **Key Parameters**:\n",
        "  - `decoder_pab_channels`: Number of channels for the PAB module in the decoder.\n",
        "  - Additional parameters similar to Unet."
      ],
      "metadata": {
        "id": "5CVUZ0-wu52L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.MAnet('resnet34', encoder_depth=4, decoder_channels=decoder_channels, classes=4, aux_params=aux_params)\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(1, 3, 256, 256)  # example input (batch size, channels, height, width)\n",
        "\n",
        "# Get the output\n",
        "mask, label = model(x)\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "print(mask.shape)  # Should be (1, num_classes, height, width)\n",
        "print(label.shape)  # Should be (1, num_aux_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j03Vj7IVu6Vm",
        "outputId": "4a56c44d-2fee-4a53-85e3-6151f1eee82f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 256, 256])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5ZNPZoJxlH4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IS8Q9U2bu37w"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Linknet\n",
        "- **Class**: `segmentation_models_pytorch.Linknet`\n",
        "- **Description**: Linknet is a lightweight architecture designed for fast inference, using summation for fusing decoder blocks with skip connections.\n",
        "- **Key Parameters**: Similar to Unet."
      ],
      "metadata": {
        "id": "UyP3Ztleu3wL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = smp.Linknet('resnet34', classes=4, aux_params=aux_params)\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(1, 3, 256, 256)  # example input (batch size, channels, height, width)\n",
        "\n",
        "# Get the output\n",
        "mask, label = model(x)\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "print(mask.shape)  # Should be (1, num_classes, height, width)\n",
        "print(label.shape)  # Should be (1, num_aux_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnxocBBiu3lW",
        "outputId": "712d45cc-fc95-479c-af31-0db27c5d0694"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 256, 256])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Q_AolzKxlys"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. FPN\n",
        "- **Class**: `segmentation_models_pytorch.FPN`\n",
        "- **Description**: Feature Pyramid Network (FPN) uses a pyramid structure to enhance the features extracted by the encoder.\n",
        "- **Key Parameters**:\n",
        "  - `decoder_pyramid_channels`: Number of convolution filters in the FPN.\n",
        "  - `decoder_segmentation_channels`: Number of convolution filters in the segmentation blocks.\n",
        "  - `decoder_merge_policy`: How to merge pyramid features (options: `add`, `cat`).\n",
        "  - `decoder_dropout`: Spatial dropout rate for the FPN.\n",
        "  - Additional parameters similar to Unet."
      ],
      "metadata": {
        "id": "p7X79ZKzxmDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the model\n",
        "model = smp.FPN('resnet34', classes=4, aux_params=aux_params)\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(1, 3, 256, 256)  # example input (batch size, channels, height, width)\n",
        "\n",
        "# Get the output\n",
        "mask, label = model(x)\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "print(mask.shape)  # Should be (1, num_classes, height, width)\n",
        "print(label.shape)  # Should be (1, num_aux_classes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0bxIDsvxlv4",
        "outputId": "f59ac6bf-8d3e-4b5b-c422-9ae77f475cb2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 256, 256])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Prp7rm-Rxlt_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation and Corrected Code for Each Model\n",
        "\n",
        "#### Common Issue I fased and Solution:\n",
        "The error occurs due to using a batch size of 1 when training, which is incompatible with batch normalization layers. Batch normalization layers require a batch size greater than 1 to calculate meaningful statistics. The solution involves either increasing the batch size or switching the model to evaluation mode for inference.\n",
        "\n",
        "---\n",
        "\n",
        "#### DeepLabV3\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "- **Auxiliary Parameters:** Configures the auxiliary classification output, which adds an additional classification head to the model.\n",
        "- **Model Creation:** Creates a DeepLabV3 model with a ResNet34 encoder.\n",
        "- **Input Tensor:** Defines the input tensor with random values. Here, we use a batch size of 4 to avoid issues with batch normalization.\n",
        "- **Output Handling:** Checks if the output is a tuple (when auxiliary parameters are used) and prints the shapes of the outputs.\n",
        "\n",
        "---\n",
        "\n",
        "#### DeepLabV3+\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "- **Auxiliary Parameters:** Configures the auxiliary classification output.\n",
        "- **Model Creation:** Creates a DeepLabV3+ model with a ResNet34 encoder.\n",
        "- **Model Evaluation Mode:** Sets the model to evaluation mode, which changes the behavior of certain layers like batch normalization.\n",
        "- **Input Tensor:** Defines the input tensor with random values.\n",
        "- **Output Handling:** Checks if the output is a tuple and prints the shapes of the outputs.\n",
        "\n",
        "---\n",
        "\n",
        "#### PAN\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "- **Auxiliary Parameters:** Configures the auxiliary classification output.\n",
        "- **Model Creation:** Creates a PAN model with a ResNet34 encoder.\n",
        "- **Options:** Provides two options based on whether the model is used for training or inference.\n",
        "  - **Training Mode:** Increase the batch size to more than 1 to avoid issues with batch normalization.\n",
        "  - **Evaluation Mode:** Set the model to evaluation mode to use batch normalization with a batch size of 1.\n",
        "\n",
        "---\n",
        "\n",
        "#### Summary\n",
        "\n",
        "- **DeepLabV3 and DeepLabV3+:** Use appropriate auxiliary parameters and check for tuple output. Adjust batch size as needed and use evaluation mode for inference to avoid batch normalization issues.\n",
        "- **PAN:** Increase batch size for training or use evaluation mode for inference to avoid batch normalization issues.\n"
      ],
      "metadata": {
        "id": "cvid_Xcu44j8"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hSE_lvgcxvey"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 7. PAN\n",
        "- **Class**: `segmentation_models_pytorch.PAN`\n",
        "- **Description**: Pyramid Attention Network (PAN) focuses on aggregating multi-scale features with global attention mechanisms.\n",
        "- **Key Parameters**:\n",
        "  - `encoder_output_stride`: Determines the downsampling factor in the encoder.\n",
        "  - `decoder_channels`: Number of convolution filters in the decoder.\n",
        "  - Additional parameters similar to Unet.\n"
      ],
      "metadata": {
        "id": "_1uD2cS0yKKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **For Training (Increase Batch Size)**"
      ],
      "metadata": {
        "id": "Mfs0YC0d2i9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Define auxiliary parameters\n",
        "aux_params = dict(\n",
        "    pooling='avg',\n",
        "    dropout=0.5,\n",
        "    activation='sigmoid',\n",
        "    classes=4,\n",
        ")\n",
        "\n",
        "# Create the model with supported encoder output stride\n",
        "model = smp.PAN(\n",
        "    encoder_name='resnet34',\n",
        "    encoder_output_stride=16,  # Correct stride\n",
        "    classes=4,\n",
        "    aux_params=aux_params\n",
        ")\n",
        "\n",
        "# Define input tensor 'x' with random values for a larger batch size\n",
        "x = torch.randn(4, 3, 256, 256)  # Increase batch size from 1 to 4\n",
        "\n",
        "# Get the output\n",
        "output = model(x)\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "if isinstance(output, tuple):\n",
        "    mask, label = output\n",
        "    print(mask.shape)\n",
        "    print(label.shape)\n",
        "else:\n",
        "    mask = output\n",
        "    print(mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAMIUqZiyJ8K",
        "outputId": "b17eb3dd-0dfc-4296-82cb-06ff9fd18896"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4, 256, 256])\n",
            "torch.Size([4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H6Y982A9yGIe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **For Inference (Use Evaluation Mode)**\n"
      ],
      "metadata": {
        "id": "fwPFPuyN2dbo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "__ZZJeOZ2bLp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Define auxiliary parameters\n",
        "aux_params = dict(\n",
        "    pooling='avg',\n",
        "    dropout=0.5,\n",
        "    activation='sigmoid',\n",
        "    classes=4,\n",
        ")\n",
        "\n",
        "# Create the model with supported encoder output stride\n",
        "model = smp.PAN(\n",
        "    encoder_name='resnet34',\n",
        "    encoder_output_stride=16,\n",
        "    classes=4,\n",
        "    aux_params=aux_params\n",
        ")\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(1, 3, 256, 256)  # Can use a batch size of 1 in evaluation mode\n",
        "\n",
        "# Get the output\n",
        "output = model(x)\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "if isinstance(output, tuple):\n",
        "    mask, label = output\n",
        "    print(mask.shape)\n",
        "    print(label.shape)\n",
        "else:\n",
        "    mask = output\n",
        "    print(mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMqUmr8w2bI2",
        "outputId": "0688286f-8f82-4561-8d15-c5cd49991061"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 256, 256])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e0zcH5cL2bHA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. DeepLabV3\n",
        "- **Class**: `segmentation_models_pytorch.DeepLabV3`\n",
        "- **Description**: DeepLabV3 utilizes atrous convolution to capture multi-scale context by increasing the receptive field.\n",
        "- **Key Parameters**: Similar to Unet."
      ],
      "metadata": {
        "id": "wH8WkvWYxwNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define auxiliary parameters\n",
        "aux_params = dict(\n",
        "    pooling='avg',  # Consider changing or removing this if the error persists\n",
        "    dropout=0.5,\n",
        "    activation='sigmoid',\n",
        "    classes=4,\n",
        ")\n",
        "\n",
        "# Create the model\n",
        "model = smp.DeepLabV3(\n",
        "    encoder_name='resnet34',\n",
        "    classes=4,\n",
        "    aux_params=aux_params  # Set to None if you want to disable the auxiliary classifier\n",
        ")\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(4, 3, 256, 256)  # Increased batch size\n",
        "\n",
        "# Get the output\n",
        "output = model(x)  # Adjust based on whether aux_params is None or not\n",
        "\n",
        "# Check outputs\n",
        "if isinstance(output, tuple):\n",
        "    mask, label = output\n",
        "    print(mask.shape, label.shape)\n",
        "else:\n",
        "    mask = output\n",
        "    print(mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfiF7iulxlqv",
        "outputId": "13f5a94a-4c8e-4d76-9c65-de62a3e24b24"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 4, 256, 256]) torch.Size([4, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Go4Yr6eAy2fX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ve_T7qcky2OA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 9. DeepLabV3+\n",
        "- **Class**: `segmentation_models_pytorch.DeepLabV3Plus`\n",
        "- **Description**: An enhanced version of DeepLabV3, which includes a decoder module to improve object localization.\n",
        "- **Key Parameters**: Similar to Unet.\n"
      ],
      "metadata": {
        "id": "mT4gggQHyGXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "# Define auxiliary parameters\n",
        "aux_params = dict(\n",
        "    pooling='avg',  # Adjust based on the required output size\n",
        "    dropout=0.5,\n",
        "    activation='sigmoid',\n",
        "    classes=4,\n",
        ")\n",
        "\n",
        "# Create the model\n",
        "model = smp.DeepLabV3Plus(\n",
        "    encoder_name='resnet34',\n",
        "    classes=4,\n",
        "    aux_params=aux_params\n",
        ")\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Define input tensor 'x' with random values\n",
        "x = torch.randn(1, 3, 256, 256)  # example input (batch size, channels, height, width)\n",
        "\n",
        "# Get the output\n",
        "output = model(x)  # Handle output based on whether aux_params is used\n",
        "\n",
        "# Print the shapes of the outputs\n",
        "if isinstance(output, tuple):\n",
        "    mask, label = output\n",
        "    print(mask.shape)\n",
        "    print(label.shape)\n",
        "else:\n",
        "    mask = output\n",
        "    print(mask.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWEgLt4-yGFq",
        "outputId": "963a3c71-8747-433c-a635-584aed1a2e0f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4, 256, 256])\n",
            "torch.Size([1, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wMwy_YyIyGDl"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}